{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35fbb613",
   "metadata": {},
   "source": [
    "Em um alto nível, LeNet (LeNet-5) consiste em duas partes: (i) um codificador convolucional que consiste em duas camadas convolucionais; e (ii) um bloco denso que consiste em três camadas totalmente conectadas\n",
    "\n",
    "<img src=\"./img/lenet.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c9ad36",
   "metadata": {},
   "source": [
    "As unidades básicas em cada bloco convolucional são uma camada convolucional, uma função de ativação sigmoid e uma subsequente operação média de pooling. Cada camada convolucional usa um kernel e uma função de ativação sigmoid. Essas camadas mapeiam entradas organizadas espacialmente a uma série de mapas de recursos bidimensionais, normalmente aumentando o número de canais. A primeira camada convolucional tem 6 canais de saída, enquanto o segundo tem 16. Cada operação de pooling (passo 2) reduz a dimensionalidade por um fator de por meio da redução da resolução espacial. O bloco convolucional emite uma saída com forma dada por (tamanho do lote, número de canal, altura, largura)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca393268",
   "metadata": {},
   "source": [
    "Para passar a saída do bloco convolucional para o bloco denso, devemos nivelar cada exemplo no minibatch. Em outras palavras, pegamos essa entrada quadridimensional e a transformamos na entrada bidimensional esperada por camadas totalmente conectadas: como um lembrete, a representação bidimensional que desejamos usa a primeira dimensão para indexar exemplos no minibatch e o segundo para dar a representação vetorial plana de cada exemplo. O bloco denso do LeNet tem três camadas totalmente conectadas, com 120, 84 e 10 saídas, respectivamente. Porque ainda estamos realizando a classificação, a camada de saída de 10 dimensões corresponde ao número de classes de saída possíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d24f3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Oculta avisos (warnings) do TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def net():\n",
    "    return tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=6, kernel_size=5, activation='sigmoid',\n",
    "                               padding='same'),\n",
    "        tf.keras.layers.AvgPool2D(pool_size=2, strides=2),\n",
    "        tf.keras.layers.Conv2D(filters=16, kernel_size=5,\n",
    "                               activation='sigmoid'),\n",
    "        tf.keras.layers.AvgPool2D(pool_size=2, strides=2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(120, activation='sigmoid'),\n",
    "        tf.keras.layers.Dense(84, activation='sigmoid'),\n",
    "        tf.keras.layers.Dense(10)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c23f35c",
   "metadata": {},
   "source": [
    "Tomamos uma pequena liberdade com o modelo original, removendo a ativação gaussiana na camada final. Fora isso, esta rede corresponde a arquitetura LeNet-5 original. **É possível alterar a rede para tentar implementar melhorias e/ou otimizações**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab410ead",
   "metadata": {},
   "source": [
    "Ao passar a imagem por um canal único (preto e branco) através da rede e imprimir a forma de saída em cada camada, podemos inspecionar o modelo para ter certeza que suas operações se alinham com o que esperamos\n",
    "\n",
    "<img src ='./img/lenet-vert.svg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eddfb36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2D output shape: \t (1, 28, 28, 6)\n",
      "AveragePooling2D output shape: \t (1, 14, 14, 6)\n",
      "Conv2D output shape: \t (1, 10, 10, 16)\n",
      "AveragePooling2D output shape: \t (1, 5, 5, 16)\n",
      "Flatten output shape: \t (1, 400)\n",
      "Dense output shape: \t (1, 120)\n",
      "Dense output shape: \t (1, 84)\n",
      "Dense output shape: \t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.uniform((1, 28, 28, 1))\n",
    "for layer in net().layers:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape: \\t', X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009cc67c",
   "metadata": {},
   "source": [
    "Observe que a altura e largura da representação em cada camada ao longo do bloco convolucional é reduzido (em comparação com a camada anterior). A primeira camada convolucional usa 2 pixels de preenchimento para compensar a redução de altura e largura que de outra forma resultaria do uso de um kernel . Em contraste, a segunda camada convolucional dispensa o preenchimento, e, portanto, a altura e a largura são reduzidas em 4 pixels. Conforme subimos na pilha de camadas, o número de canais aumenta camada sobre camada de 1 na entrada a 6 após a primeira camada convolucional e 16 após a segunda camada convolucional. No entanto, cada camada de pooling divide a altura e a largura pela metade. Finalmente, cada camada totalmente conectada reduz a dimensionalidade, finalmente emitindo uma saída cuja dimensão corresponde ao número de classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c615a496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carregar o conjunto de dados\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Dividir o conjunto de treinamento em treino e validação (20% para validação)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Agora temos:\n",
    "# - x_train, y_train -> dados de treino\n",
    "# - x_val, y_val -> dados de validação\n",
    "# - x_test, y_test -> dados de teste\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dc44b7",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fd32836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class TrainCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Callback para visualizar o progresso do treinamento.\"\"\"\n",
    "    def __init__(self, net, train_iter, test_iter, num_epochs, device_name):\n",
    "        self.start_time = None\n",
    "        self.epoch_times = []\n",
    "        self.net = net\n",
    "        self.train_iter = train_iter\n",
    "        self.test_iter = test_iter\n",
    "        self.num_epochs = num_epochs\n",
    "        self.device_name = device_name\n",
    "\n",
    "        # Configuração do gráfico de perda e acurácia\n",
    "        self.fig, self.ax = plt.subplots()\n",
    "        self.ax.set_xlabel(\"Epoch\")\n",
    "        self.ax.set_xlim(1, num_epochs)\n",
    "        self.ax.set_ylabel(\"Metrics\")\n",
    "        self.ax.legend([\"Train Loss\", \"Train Acc\", \"Test Acc\"])\n",
    "        self.metrics = {\"train_loss\": [], \"train_acc\": [], \"test_acc\": []}\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        end_time = time.time()\n",
    "        self.epoch_times.append(end_time - self.start_time)\n",
    "\n",
    "        test_acc = self.net.evaluate(self.test_iter, verbose=0, return_dict=True)['accuracy']\n",
    "        self.metrics[\"train_loss\"].append(logs[\"loss\"])\n",
    "        self.metrics[\"train_acc\"].append(logs[\"accuracy\"])\n",
    "        self.metrics[\"test_acc\"].append(test_acc)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{self.num_epochs}: '\n",
    "              f'Loss {logs[\"loss\"]:.3f}, Train Acc {logs[\"accuracy\"]:.3f}, '\n",
    "              f'Test Acc {test_acc:.3f}')\n",
    "\n",
    "        # Atualiza o gráfico\n",
    "        self.ax.clear()\n",
    "        self.ax.set_xlabel(\"Epoch\")\n",
    "        self.ax.set_xlim(1, self.num_epochs)\n",
    "        self.ax.set_ylabel(\"Metrics\")\n",
    "        self.ax.plot(range(1, epoch + 2), self.metrics[\"train_loss\"], label=\"Train Loss\")\n",
    "        self.ax.plot(range(1, epoch + 2), self.metrics[\"train_acc\"], label=\"Train Acc\")\n",
    "        self.ax.plot(range(1, epoch + 2), self.metrics[\"test_acc\"], label=\"Test Acc\")\n",
    "        self.ax.legend()\n",
    "        plt.pause(0.01)  # Atualiza o gráfico dinamicamente\n",
    "\n",
    "        if epoch == self.num_epochs - 1:\n",
    "            batch_size = next(iter(self.train_iter))[0].shape[0]\n",
    "            num_examples = batch_size * tf.data.experimental.cardinality(self.train_iter).numpy()\n",
    "            avg_time = sum(self.epoch_times) / len(self.epoch_times)\n",
    "            print(f'{num_examples / avg_time:.1f} examples/sec on {self.device_name}')\n",
    "\n",
    "def train_ch6(net_fn, train_iter, test_iter, num_epochs, lr, device):\n",
    "    \"\"\"Treina um modelo com GPU.\"\"\"\n",
    "    strategy = tf.distribute.OneDeviceStrategy(device)  # Use a string diretamente\n",
    "\n",
    "    with strategy.scope():\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        net = net_fn()\n",
    "        net.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "    callback = TrainCallback(net, train_iter, test_iter, num_epochs, device)\n",
    "    net.fit(train_iter, epochs=num_epochs, verbose=0, callbacks=[callback])\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "208b9246",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"conv2d_8\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (32, 28, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/GPU:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlist_physical_devices(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/CPU:0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m lr, num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain_ch6\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 68\u001b[0m, in \u001b[0;36mtrain_ch6\u001b[0;34m(net_fn, train_iter, test_iter, num_epochs, lr, device)\u001b[0m\n\u001b[1;32m     65\u001b[0m     net\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39mloss, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     67\u001b[0m callback \u001b[38;5;241m=\u001b[39m TrainCallback(net, train_iter, test_iter, num_epochs, device)\n\u001b[0;32m---> 68\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m net\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/input_spec.py:202\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mmin_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ndim \u001b[38;5;241m<\u001b[39m spec\u001b[38;5;241m.\u001b[39mmin_ndim:\n\u001b[0;32m--> 202\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    203\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    204\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    205\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected min_ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mmin_ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    206\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m         )\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# Check dtype.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"conv2d_8\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (32, 28, 28)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"/GPU:0\" if tf.config.list_physical_devices('GPU') else \"/CPU:0\"\n",
    "\n",
    "lr, num_epochs = 0.9, 10\n",
    "train_ch6(net, x_train, x_test, num_epochs, lr, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dedf29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
